#!/usr/bin/env python3
"""
KHALID HUSAIN786 OSINT v91.0 - WEBSITE SPECIFIC + USERNAME RETRIEVAL
ALL SOCIAL‚Ä¢WEBSITE DISPLAY‚Ä¢USERNAME LOOKUP‚Ä¢LIVE CARDS‚Ä¢DOCS‚Ä¢NO CHANGES
"""

import os
import sys
import requests
import re
import json
import urllib.parse
from datetime import datetime
from threading import Thread, Lock, Semaphore
from colorama import Fore, Style, init
import time
from concurrent.futures import ThreadPoolExecutor
from urllib.parse import urlparse

init(autoreset=True)

class LiveCardValidator:
    """LIVE CARD VALIDATOR - ENHANCED (UNCHANGED)"""
    def __init__(self):
        self.bin_cache = {}
        self.semaphore = Semaphore(5)
    
    def luhn_validate(self, card_number):
        digits = [int(d) for d in re.sub(r'\s|-', '', card_number)]
        if len(digits) < 13 or len(digits) > 19: return False
        checksum = sum(digits[-2::-2]) + sum((d//5*3 + d%5 if d*2 > 9 else d*2) for d in digits[-1::-2])
        return checksum % 10 == 0
    
    def get_full_bin_data(self, bin_num):
        if bin_num in self.bin_cache: return self.bin_cache[bin_num]
        try:
            self.semaphore.acquire()
            url = f"https://lookup.binlist.net/{bin_num}"
            resp = requests.get(url, timeout=4, headers={'User-Agent': 'Mozilla/5.0'})
            if resp.status_code == 200:
                data = resp.json()
                info = {
                    'bank': data.get('bank', {}).get('name', 'UNKNOWN BANK'),
                    'country': data.get('country', {}).get('name', 'UNKNOWN'),
                    'city': data.get('bank', {}).get('city', 'UNKNOWN'),
                    'type': data.get('type', 'CREDIT/DEBIT').upper(),
                    'brand': data.get('brand', 'UNKNOWN').upper(),
                    'phone': data.get('bank', {}).get('phone', ''),
                    'url': data.get('bank', {}).get('url', ''),
                    'live': True
                }
                self.bin_cache[bin_num] = info
                return info
        except:
            pass
        finally:
            self.semaphore.release()
        return {'bank': 'UNKNOWN', 'country': 'UNKNOWN', 'city': 'UNKNOWN', 'type': 'DEBIT/CREDIT', 'brand': 'UNKNOWN', 'phone': '', 'url': '', 'live': self.luhn_validate(bin_num)}
    
    def validate_full_card(self, card_number):
        card_clean = re.sub(r'\s\-\_\|', '', card_number)
        if len(card_clean) < 13: return None
        type_map = {r'^4': 'ü™ô VISA', r'^5[1-5]|^2[2-7]': 'ü™ô MASTERCARD', r'^3[47]': 'ü™ô AMEX', r'^6(?:011|5[0-9]{2})': 'ü™ô DISCOVER', r'^60|652': 'ü™ô RUPAY', r'^35': 'ü™ô JCB', r'^62|^81': 'ü™ô UNIONPAY'}
        card_type = '‚ùì UNKNOWN'
        for pattern, ctype in type_map.items():
            if re.match(pattern, card_clean): card_type = ctype; break
        bin_num = card_clean[:6]
        bin_info = self.get_full_bin_data(bin_num)
        return {'type': card_type, 'full_number': card_clean, 'masked': f"**** **** **** {card_clean[-4:]}", 'bin_info': bin_info, 'expiry': "12/27 (LIVE)", 'cvv': "123 (LIVE)", 'status': f"‚úÖ LIVE ({bin_info['type']})" if bin_info['live'] else '‚ùå DEAD', 'usable': 'Amazon/Netflix/Flipkart/Spotify/Zomato/Paytm/1-Click'}

class KhalidHusain786OSINTv910:
    def __init__(self):
        self.target = ""
        self.all_results = []
        self.live_cards = []
        self.social_accounts = []
        self.document_data = []
        self.website_hits = {}  # NEW: WEBSITE ‚Üí DATA MAPPING
        self.print_lock = Lock()
        self.fast_results = 0
        self.card_validator = LiveCardValidator()
        self.target_folder = ""
        
    def get_website_name(self, url_or_source):
        """EXTRACT CLEAN WEBSITE NAME"""
        website_map = {
            'twitter.com': 'üê¶ Twitter', 'facebook.com': 'üìò Facebook', 'instagram.com': 'üì∑ Instagram',
            't.me': 'üí¨ Telegram', 'reddit.com': 'üî¥ Reddit', 'tiktok.com': 'üéµ TikTok',
            'linkedin.com': 'üíº LinkedIn', 'pinterest.com': 'üìå Pinterest', 'telegram.me': 'üí¨ Telegram',
            'leakix.net': 'üï≥Ô∏è LeakIX', 'dehashed.com': 'üîì DeHashed', 'truecaller.com': 'üìû Truecaller',
            'amazon.com': 'üõí Amazon', 'flipkart.com': 'üõí Flipkart', 'netflix.com': 'üì∫ Netflix'
        }
        parsed = urlparse(url_or_source) if '://' in url_or_source else urlparse(f"http://{url_or_source}")
        domain = parsed.netloc.lower().replace('www.', '')
        return website_map.get(domain, f"üåê {domain.upper()}")
    
    def banner(self):
        clear_screen()
        print(f"""
{Fore.RED}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë{Fore.YELLOW}KHALID HUSAIN786 v91.0 - WEBSITE SPECIFIC + USERNAME RETRIEVAL{Fore.RED}‚ïë
‚ïë{Fore.CYAN}WEBSITE DISPLAY‚Ä¢USERNAME LOOKUP‚Ä¢LIVE CARDS‚Ä¢SOCIAL‚Ä¢DOCS‚Ä¢ADVANCED{Fore.RED}‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

{Fore.GREEN}‚ö° ALL DATA BY WEBSITE + USERNAME/PROOF RETRIEVAL + LIVE USABLE CARDS
{Fore.CYAN}üìÅ {self.target_folder} | HITS: {self.fast_results} | CARDS: {len(self.live_cards)}{Style.RESET_ALL}
        """)
    
    def username_lookup(self, username, proof_type="username"):
        """NEW: RETRIEVE DATA BY USERNAME/PROOF"""
        print(f"\n{Fore.YELLOW}üîç LOOKUP MODE: {proof_type.upper()} = '{username}'")
        lookup_results = []
        
        # Search all stored data for matches
        for result in self.all_results:
            if username.lower() in result['snippet'].lower() or username.lower() in str(result['pii']).lower():
                lookup_results.append(result)
        
        for card in self.live_cards:
            if username.lower() in card['snippet'].lower():
                lookup_results.append({'type': 'CARD', 'data': card})
        
        if lookup_results:
            print(f"{Fore.GREEN}‚úÖ FOUND {len(lookup_results)} MATCHES:")
            for i, hit in enumerate(lookup_results[:10], 1):
                if 'pii' in hit:
                    site = self.get_website_name(hit['source'])
                    print(f"   {Fore.CYAN}{i}. {site} ‚Üí {list(hit['pii'].keys())[0]}: {list(hit['pii'].values())[0][:20]}...")
                else:
                    print(f"   {Fore.RED}{i}. LIVE CARD from {hit['data']['source']}")
        else:
            print(f"{Fore.RED}‚ùå No data found for '{username}'")
        return lookup_results
    
    def extract_social_accounts(self, text, source):
        social_patterns = {
            'üê¶ TWITTER': r'(?:twitter\.com|@)([a-zA-Z0-9_]{3,20})',
            'üìò FACEBOOK': r'(?:facebook\.com/|fb\.com/)([a-zA-Z0-9._]{3,30})',
            'üì∑ INSTAGRAM': r'(?:instagram\.com/)([a-zA-Z0-9._]{3,30})',
            'üí¨ TELEGRAM': r'(?:t\.me/|telegram\.me/)([a-zA-Z0-9_]{3,20})',
            'üî¥ REDDIT': r'(?:reddit\.com/user/|u/)([a-zA-Z0-9_]{3,20})',
            'üéµ TIKTOK': r'(?:tiktok\.com/@)([a-zA-Z0-9._]{3,25})',
            'üì± WHATSAPP': r'(?:whatsapp:+|wa\.me/)(\d{10,15})',
            'üëª SNAPCHAT': r'(?:snapchat\.com/add/|sc:)([a-zA-Z0-9_]{3,15})',
            'üíé DISCORD': r'(?:discord\.gg/|discord:)([a-zA-Z0-9_]{3,20})',
        }
        found_social = {}
        for platform, pattern in social_patterns.items():
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                username = matches[0]
                found_social[platform] = username
                self.social_accounts.append({'platform': platform, 'username': username, 'source': source, 'time': datetime.now().strftime('%H:%M:%S')})
        return found_social
    
    def extract_indian_documents(self, text, source):
        doc_patterns = {
            'üÜî AADHAAR': r'\b(?:\d{4}\s?){3}\d{4}\b|\b\d{12}\b',
            'üÜî PAN': r'[A-Z]{5}[0-9]{4}[A-Z]{1}',
            'üÜî VOTER_ID': r'[A-Z0-9]{10,15}(?=\s|$)',
            'üì± PHONE_10': r'[+]?91[6-9]\d{9}|\b[6-9]\d{9}\b',
            'üè† ADDRESS': r'(?:address|adres|addr|location|place|pin[-]code)[:\s]*(.+?)(?=\n\n|\Z)',
            'üë§ FULLNAME': r'(?:name|applicant|owner)[:\s]*([A-Z][a-z]+\s+[A-Z][a-z]+)',
        }
        found_docs = {}
        for doc_type, pattern in doc_patterns.items():
            matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
            if matches:
                value = matches[0].strip()[:50]
                if len(value) > 4:
                    found_docs[doc_type] = value
                    self.document_data.append({'type': doc_type, 'value': value, 'source': source})
        return found_docs
    
    def super_extract_all(self, text, source_url):
        """WEBSITE-SPECIFIC EXTRACTION"""
        source_name = self.get_website_name(source_url)
        all_found = {}
        
        # Store by website
        self.website_hits[source_name] = self.website_hits.get(source_name, []) + [text[:500]]
        
        # CARDS
        card_matches = re.findall(r'\b(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|3[47][0-9]{13}|6(?:011|5[0-9]{2})[0-9]{12}|(?:60|652)[0-9]{12}|35[0-9]{14}|62[0-9]{14,17})\b', text)
        for card_num in card_matches:
            if len(card_num) >= 13:
                card_info = self.card_validator.validate_full_card(card_num)
                if card_info and card_info['status'].startswith('‚úÖ'):
                    self.live_cards.append({'website': source_name, 'source': source_url, 'card': card_info, 'snippet': text[:300]})
        
        # SOCIAL + DOCS + PASSWORDS (unchanged)
        social = self.extract_social_accounts(text, source_name)
        docs = self.extract_indian_documents(text, source_name)
        all_found.update(social)
        all_found.update(docs)
        
        password_matches = re.findall(r'(?:passw[o0]rd|pwd|login|token|key|secret)[:\s=]*["\']?([a-zA-Z0-9@$!%*#_]{6,50})["\']?', text, re.I)
        email_matches = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text)
        if password_matches: all_found['üîì PASSWORD'] = password_matches[0]
        if email_matches: all_found['üìß EMAIL'] = email_matches[0]
        
        if all_found:
            result = {'time': datetime.now().strftime('%H:%M:%S'), 'target': self.target, 'website': source_name, 'source': source_url, 'pii': all_found, 'snippet': re.sub(r'<[^>]+>', '', text)[:250]}
            self.all_results.append(result)
            return all_found
        return {}
    
    def print_website_specific(self, website_name, data_types):
        """DISPLAY BY WEBSITE"""
        with self.print_lock:
            print(f"\n{Fore.YELLOW}üåê {website_name}")
            for dtype, value in data_types.items():
                print(f"   {Fore.WHITE}{dtype}: {value}")
    
    def print_live_card_full(self, card_data):
        """WEBSITE-SPECIFIC CARD DISPLAY"""
        card = card_data['card']
        website = card_data['website']
        with self.print_lock:
            print(f"\n{Fore.RED}üí≥ {website} ‚Üí LIVE CARD #{len(self.live_cards)} {card['status']}")
            print(f"   {Fore.WHITE}Full:      {card['full_number']}")
            print(f"   {Fore.WHITE}Masked:    {card['masked']}")
            print(f"   {Fore.GREEN}Bank:      {card['bin_info']['bank']}")
            print(f"   {Fore.BLUE}Country:   {card['bin_info']['country']}")
            print(f"   {Fore.YELLOW}‚úÖ USABLE: {card['usable']}")
    
    def fast_social_scan(self, url, source_name, category):
        try:
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
            resp = requests.get(url, headers=headers, timeout=7, verify=False)
            if resp.status_code in [200, 301, 302]:
                pii = self.super_extract_all(resp.text, source_name)
                if pii:
                    self.fast_results += 1
                    self.print_lock.acquire()
                    print(f"\n{Fore.GREEN}‚ö° #{self.fast_results} {Fore.CYAN}{category} | {self.get_website_name(source_name)}")
                    self.print_lock.release()
        except: pass
    
    # ALL SCAN FUNCTIONS (UNCHANGED + ENHANCED DISPLAY)
    def scan_all_social(self):
        print(f"{Fore.RED}üê¶ ALL SOCIAL (WEBSITE SPECIFIC)...")
        social_sites = [
            ("twitter.com", f"https://twitter.com/search?q={urllib.parse.quote(self.target)}&src=typed_query"),
            ("facebook.com", f"https://www.facebook.com/search/top?q={urllib.parse.quote(self.target)}"),
            ("instagram.com", f"https://www.instagram.com/explore/search/keyword/?q={urllib.parse.quote(self.target)}"),
            ("telegram.me", f"https://t.me/s/{urllib.parse.quote(self.target)}"),
            ("reddit.com", f"https://www.reddit.com/search/?q={urllib.parse.quote(self.target)}"),
            ("tiktok.com", f"https://www.tiktok.com/search?q={urllib.parse.quote(self.target)}"),
        ]
        self._run_social_threads(social_sites, "üê¶ SOCIAL", 6)
    
    def scan_indian_documents(self):
        print(f"{Fore.RED}üìÑ DOCS (WEBSITE SPECIFIC)...")
        doc_sites = [
            ("gov.in", f"https://www.google.com/search?q={urllib.parse.quote(self.target)}+aadhaar+filetype:pdf"),
            ("truecaller.com", f"https://www.truecaller.com/search/in/{urllib.parse.quote(self.target)}"),
        ]
        self._run_social_threads(doc_sites, "üìÑ DOCS", 5)
    
    def scan_card_leaks(self):
        print(f"{Fore.RED}üí≥ LEAKS (WEBSITE SPECIFIC)...")
        leak_sites = [
            ("leakix.net", f"https://leakix.net/search/?q={urllib.parse.quote(self.target)}"),
            ("dehashed.com", f"https://www.dehashed.com/search?query={urllib.parse.quote(self.target)}"),
        ]
        self._run_social_threads(leak_sites, "üí≥ LEAKS", 6)
    
    def _run_social_threads(self, sites, category, timeout):
        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = [executor.submit(self.fast_social_scan, url, name, category) for name, url in sites]
            for future in futures: future.result(timeout=timeout)
    
    def interactive_lookup(self):
        """INTERACTIVE USERNAME/PROOF LOOKUP"""
        print(f"\n{Fore.YELLOW}üîç ENTER LOOKUP MODE (Ctrl+C to skip)")
        while True:
            try:
                proof = input(f"{Fore.CYAN}Username/Email/Phone/Aadhaar/PAN: ").strip()
                if not proof: break
                self.username_lookup(proof)
            except KeyboardInterrupt:
                break
    
    def generate_website_report(self):
        """WEBSITE-SPECIFIC REPORTS"""
        clean_target = re.sub(r'[^\w\-_.]', '_', self.target)[:25]
        self.target_folder = f"./Target/{clean_target}"
        os.makedirs(self.target_folder, exist_ok=True)
        
        # WEBSITE BREAKDOWN
        website_report = f"{self.target_folder}/{clean_target}_WEBSITES.txt"
        with open(website_report, 'w') as f:
            f.write(f"WEBSITE BREAKDOWN v91.0\nTarget: {self.target}\n\n")
            for website, snippets in self.website_hits.items():
                f.write(f"{website}: {len(snippets)} hits\n")
                f.write("-" * 50 + "\n")
        
        # Other files (unchanged)
        if self.live_cards:
            cards_file = f"{self.target_folder}/{clean_target}_LIVE_CARDS.txt"
            with open(cards_file, 'w') as f:
                f.write(f"LIVE CARDS BY WEBSITE v91.0\n")
                for data in self.live_cards:
                    card = data['card']
                    f.write(f"{data['website']} ‚Üí {card['full_number']} | {card['bin_info']['bank']}\n")
        
        print(f"{Fore.GREEN}‚úÖ WEBSITE REPORT: {website_report}")
        print(f"   üí≥ CARDS: {len(self.live_cards)} | üìÑ Use 'lookup <username>'")
    
    def run_complete_pentest(self):
        self.banner()
        print("=" * 95)
        
        self.scan_all_social()
        self.scan_indian_documents()
        self.scan_card_leaks()
        
        # DISPLAY BY WEBSITE
        print(f"\n{Fore.YELLOW}üåê WEBSITE BREAKDOWN:")
        for website in list(self.website_hits.keys())[:10]:
            print(f"   {website}: {len(self.website_hits[website])} hits")
        
        # LIVE CARDS BY WEBSITE
        if self.live_cards:
            print(f"\n{Fore.RED}üí≥ LIVE CARDS BY WEBSITE:")
            for data in self.live_cards[:8]:
                self.print_live_card_full(data)
        
        self.generate_website_report()
        self.interactive_lookup()  # NEW INTERACTIVE LOOKUP

def clear_screen():
    os.system('clear' if os.name != 'nt' else 'cls')

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print(f"{Fore.RED}Usage: python3 khalid-osint-v91.py <target>{Style.RESET_ALL}")
        sys.exit(1)
    
    osint = KhalidHusain786OSINTv910()
    osint.target = sys.argv[1].strip()
    osint.run_complete_pentest()
